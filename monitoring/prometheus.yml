# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets: []

scrape_configs:
  # FastAPI Application Metrics
  - job_name: 'dnd-api'
    static_configs:
      - targets: ['api_server:8080']
    metrics_path: '/metrics'
    scrape_interval: 15s

  # vLLM Server Metrics (if exposed)
  - job_name: 'vllm-server'
    static_configs:
      - targets: ['vllm_server:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  # System Metrics
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node_exporter:9100']
    scrape_interval: 15s

  # GPU Metrics
  - job_name: 'nvidia-gpu'
    static_configs:
      - targets: ['nvidia_gpu_exporter:9445']
    scrape_interval: 15s

  # Redis Metrics
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 15s

  # PostgreSQL Metrics (requires postgres_exporter)
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres_exporter:9187']
    scrape_interval: 30s

---
# monitoring/alert_rules.yml
groups:
  - name: dnd_alerts
    rules:
      # High GPU Memory Usage
      - alert: HighGPUMemoryUsage
        expr: nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "GPU memory usage is critically high"
          description: "GPU memory usage has been above 90% for more than 5 minutes"

      # API Response Time
      - alert: HighAPIResponseTime
        expr: histogram_quantile(0.95, rate(dnd_request_duration_seconds_bucket[5m])) > 2
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "API response time is high"
          description: "95th percentile response time is above 2 seconds"

      # High Error Rate
      - alert: HighErrorRate
        expr: rate(dnd_requests_total{status=~"5.."}[5m]) / rate(dnd_requests_total[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 10% for more than 2 minutes"

      # Model Server Down
      - alert: ModelServerDown
        expr: up{job="vllm-server"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "vLLM server is down"
          description: "The vLLM model server has been down for more than 1 minute"

      # Database Connection Issues
      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database is unreachable"
          description: "PostgreSQL database has been unreachable for more than 1 minute"

      # High CPU Usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage has been above 80% for more than 5 minutes"

      # Low Disk Space
      - alert: LowDiskSpace
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space"
          description: "Disk space is below 10% for more than 5 minutes"

---
# monitoring/grafana/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true

---
# monitoring/grafana/dashboards/dashboard.yml
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /etc/grafana/provisioning/dashboards

---
# monitoring/grafana/dashboards/dnd-dashboard.json
{
  "dashboard": {
    "id": null,
    "title": "D&D AI System Dashboard",
    "description": "Comprehensive monitoring for D&D AI system",
    "tags": ["dnd", "ai", "gaming"],
    "style": "dark",
    "timezone": "browser",
    "refresh": "30s",
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "panels": [
      {
        "id": 1,
        "title": "GPU Memory Usage",
        "type": "stat",
        "targets": [
          {
            "expr": "nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes * 100",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "steps": [
                {"color": "green", "value": 0},
                {"color": "yellow", "value": 70},
                {"color": "red", "value": 90}
              ]
            }
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "API Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(dnd_requests_total[5m])",
            "refId": "A",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "Response Time Distribution",
        "type": "heatmap",
        "targets": [
          {
            "expr": "rate(dnd_request_duration_seconds_bucket[5m])",
            "refId": "A"
          }
        ],
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 0}
      },
      {
        "id": 4,
        "title": "Active WebSocket Sessions",
        "type": "stat",
        "targets": [
          {
            "expr": "dnd_active_sessions",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "short"
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 8}
      },
      {
        "id": 5,
        "title": "Model Inference Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.5, rate(dnd_model_inference_seconds_bucket[5m]))",
            "refId": "A",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(dnd_model_inference_seconds_bucket[5m]))",
            "refId": "B",
            "legendFormat": "95th percentile"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 6, "y": 8}
      },
      {
        "id": 6,
        "title": "System Resources",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "refId": "A",
            "legendFormat": "CPU Usage %"
          },
          {
            "expr": "node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100",
            "refId": "B",
            "legendFormat": "Memory Available %"
          }
        ],
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 8}
      }
    ]
  }
}

---
# monitoring/filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/app/*.log
    fields:
      service: dnd-api
    fields_under_root: true
    json.keys_under_root: true
    json.add_error_key: true

  - type: docker
    enabled: true
    containers.ids: '*'
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "dnd-logs-%{+yyyy.MM.dd}"

setup.template.name: "dnd-logs"
setup.template.pattern: "dnd-logs-*"

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644