FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

# Install system packages
RUN apt-get update && apt-get install -y \
    python3 python3-pip curl git gcc g++ \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip
RUN python3 -m pip install --upgrade pip

# Install PyTorch for CUDA 12.1
RUN pip install torch==2.1.2+cu121 --extra-index-url https://download.pytorch.org/whl/cu121

# Install vLLM and related packages
RUN pip install \
    vllm[cuda]==0.2.7 \
    transformers \
    accelerate \
    bitsandbytes \
    "numpy < 2.0"

# Create app directory
WORKDIR /app

# Copy your optimized server script
COPY optimized_vllm_server.py .

# Create logs folder (optional)
RUN mkdir -p logs

# Expose vLLM default port
EXPOSE 8000

# Health check endpoint
HEALTHCHECK --interval=60s --timeout=30s --start-period=120s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Run the vLLM server
CMD ["python3", "optimized_vllm_server.py"]
